<div id="accordion">

    <h2>Overview</h2>

    <div>
		<p>One example of a typical distributed system is the web search engine. It is designed to search for information on the World
			Wide Web. Search results are generally presented in a list of
			results and are often called hits. PageRank [1] is a well-known web
			graph ranking algorithm that helps the Internet user sort hits by
			their importance. It calculates numerical value to each element
			of a hyperlinked set of webpages, which reflects the probability
			that the random surfer will access that page. The process
			can be understood as a Markov Chain [2] which needs iterative
			calculations to converge. One iteration of PageRank calculates the new
			access probability for each webpage based on values calculated in
			the previous iteration. The iterating will not stop until the number
			of current iterations is bigger than predefined maximum iterations,
			or the Euclidian distance between rank values in two subsequent
			iterations is less than a predefined threshold that controls the
			accuracy of the output results.</p>
		<div style="text-align:center"> 
			<img src="assets/img/hw/pagerank/webgraph.png" alt="" width="406" height="328" />
			<p>Fig.1:  Mathematical PageRank for a simple network in Wikipedia</p>
		</div><br>
		<p>Fig.1 consists of 11 vertices {A, B, C, D, E, F, G1, G2, G3, G4, G5}. Each vertex refers to a unique webpage, and the directed edge 
			means there is one link from the source webpage to a target webpage. The percentage of each vertex presents the rank value of each webpage.</p>

		<p><strong>Notes:</strong></p>
		<p>You can implement a sequential PageRank that can run on
			desktops or laptops. But when processing larger amounts of input data, like web
			graphs containing more than a million webpages, you need to run the
			application in parallel so that it can aggregate the
			computing power of multiple compute nodes. Currently, in both
			industry and academia, the study of large-scale web or social graphs has
			become increasingly popular. In one published paper, the job execution
			engines that claim to support large scale PageRank applications include: MPI,
			Hadoop, Dryad, Twister, Pregel. Project #1 is divided into two parts.
			In the first part, you need to implement the sequential version of PageRank.
			In the second part, you will implement a parallel version by
			using the programming interfaces of Hadoop MapReduce job execution
			engine.</p>
		
		<p><strong>Formula:</strong></p>
		<p>Eqn.1 is the formula to calculate the rank value for each webpage. We will learn this formula by applying it to the case in Fig.1. There are 11 webpages in Fig.1 which include: {A, B, C, D, E, F, G1, G2, G3, G4, G5}. Assuming the probability distribution for a web surfer accessing all these 11 pages in the current iteration is {PR(A), PR(B), PR(C),  … PR(G5)}, then the probability for the surfer to access Page B in the next iteration is:   
			<pre>PR(B)  =  PR(D)/2 + PR(E)/3 + PR(F)/2 + PR(C) + PR(G1)/2 + PR(G2)/2 + PR(G3)/2</pre>
			In the general case, the PageRank value for any page u can be expressed as:
			<br> Equ.1:   <img src="assets/img/hw/pagerank/eq1.png" width="150" height="20"></p>
		<p> The vertices seen in the right of the formula contain all the webpages that point to target web page ‘u’. The L(v) refers to the out degree of each webpage in the vertices set. The initial rank values of each webpage, like PR’(u), can be any double value. After several iteration calculations, the rank values converge to the stationary distribution regardless of what their initial values are [3].</p>

		<p><strong>Damping factor</strong></p>
		<p>
		The PageRank theory holds that even an imaginary surfer who is randomly clicking on links will eventually stop clicking. The probability, at any step, that the person will continue is a damping factor d. Various studies have tested different damping factors, but it is generally assumed that the damping factor will be around 0.85. The formula considering damping factor is shown in Eqn.2. N refers to the total number of the unique urls. 
		<br> Equ.2: <img src="assets/img/hw/pagerank/eq2.png" width="242" height="37"></p>
	</div>

    <h2><a>Execution guide for sample PageRank code</a></h2>
    <div>
        <p>To help you understand the process of PageRank computation better, we offer an executable PageRank java class file in the assignment package. Its usage is:  </p>
		<p><strong>Java SequentialPageRank [input file name] [output file name] [iteration count] [damping factor]</strong></p>
        <p>We also provide a small input file which is built based on the web graph showed in Fig.1. You can evaluate the rank values in Fig. 1 by running SequentialPageRank with the following parameters:</p>
        <br><pre><strong>Java  SequentialPageRank    pagerank.input   pagerank.output   10  0.85</strong></pre> 
        <p>To check the accuracy of these output rank values, you can open pagerank.output file and see whether the output results are the same as rank values in Fig. 1. Generally speaking, the larger the number of iterations, the more accurate the computed rank values will be. </p>
    </div>
    <h2><a>Programming Guide for PageRank</a></h2>

    <div>
    	<p><strong>Input Data format</strong></p>
        <p>The input data for PageRank application is the web graph in adjacency matrix format [4]. In our sample program, it transfers the web graph into a simplified adjacency matrix. The following steps were performed to construct an adjacency matrix for the web graph in Fig.1: </p>
		<ol>
			<li>Construct a set of tuples that describe the web graph
				structure: WebG = {(A,null), (B, C), (C, B) (D, A, B), (E, B D F),
				(F, B E), (G1, B E), (G2, B E), (G3, B E), (G4, E), (G5, E)</li>
			<li>Map letters to numbers. A->0, B->1, C->2, D->3, E->4, F->5,
				G1->6, G2->7, G3->8, G4->9, G5->10</li>
			<li>Construct the simplified adjacency matrix based on
				information in step 1,2. 
				<p>0</p>
				<p>1 2</p>
				<p>2 1</p>
				<p>3 0 1</p>
				<p>4 1 3 5</p>
				<p>5 1 4</p>
				<p>6 1 4</p>
				<p>7 1 4</p>
				<p>8 1 4</p>
				<p>9 4</p>
				<p>10 4</p>
			</li>
		</ol>
	</div>
    <h2><a> References </a></h2>

	<ol>		
		<li>
			<a href="http://en.wikipedia.org/wiki/PageRank">http://en.wikipedia.org/wiki/PageRank</a>
		</li>
		<li>
			<a href="http://en.wikipedia.org/wiki/Markov_chain">http://en.wikipedia.org/wiki/Markov_chain</a>
		</li>
		<li>
			Sergey Brin and Lawrence Page, <a
				href="http://infolab.stanford.edu/~backrub/google.html">The
				Anatomy of a Large-Scale </a><a
				href="http://infolab.stanford.edu/~backrub/google.html">Hypertextual</a>
			<a href="http://infolab.stanford.edu/~backrub/google.html"> Web
				Search Engine</a>, Stanford University, WWW7 Proceedings of the seventh
			international conference on World Wide Web 7 , 1998
		</li>
		<li>
			<a href="http://en.wikipedia.org/wiki/Adjacency_matrix">http://en.wikipedia.org/wiki/Adjacency_matrix</a>
		</li>
	
	</ol>	
</div>
