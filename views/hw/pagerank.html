<div id="accordion">
    <h2>Goal</h2>
    <div>
        <p>The goal of this assignment is to implement the PageRank algorithm. We will only
            focus on the sequential version of the algorithm and reserve the parallel version for
            later.</p>
    </div>

    <h2>Deliverable</h2>
    <div><p>You will write the program in Java/C and submit an executable with documentation on how to run it. </p></div>

    <h2>Evaluation</h2>
    <div><p>TBD</p></div>

    <h2>Introduction</h2>

    <div>
		<p>One example of a typical distributed system is the web search engine. 
			Search results are generally presented in a list and are often called hits. 
			PageRank [1] is a well-known web
			graph ranking algorithm that helps the Internet user sort hits by
			their importance. It calculates numerical value to each element
			of a hyperlinked set of webpages which reflects the probability
			that a random surfer will access that page. The process
			can be understood as a Markov Chain [2] which requires iterative
			calculations to converge. One iteration of PageRank calculates the new
			access probability for each webpage based on values derived from
			the previous iteration. Iterating will not stop until the number
			of current iterations has exceeded predefined maximum iterations,
			or the Euclidian distance between rank values in two subsequent
			iterations is less than a predefined threshold that controls the
			accuracy of the output results.</p>
		<div style="text-align:center"> 
			<img src="assets/img/hw/pagerank/webgraph.png" alt="" width="406" height="328" />
			<p>Fig.1:  Mathematical PageRank for a simple network in Wikipedia</p>
		</div><br>
		<p>Fig.1 consists of 11 vertices {A, B, C, D, E, F, G1, G2, G3, G4, G5}. Each vertex refers to a unique webpage, and the directed edge 
			means there is one link from the source webpage to a target webpage. The included percentage indicates the rank value of each webpage.</p>

		<p><strong>Notes:</strong></p>
		<p> This project is divided into two parts.
			In the first part, you need to implement the sequential version of PageRank.
			In the second you will implement a parallel version by
			using the programming interfaces of Hadoop MapReduce job execution
			engine.</p>
		
		<p><strong>Formula:</strong></p>
		<p>Eqn.1 is the formula to calculate the rank value for each webpage. We will learn this formula by applying it to the case in Fig.1. There are 11 webpages in Fig.1 which include: {A, B, C, D, E, F, G1, G2, G3, G4, G5}. Assuming the probability distribution for a web surfer accessing all these 11 pages in the current iteration is {PR(A), PR(B), PR(C),  … PR(G5)}, then the probability for the surfer to access Page B in the next iteration is:   
			<pre>PR(B)  =  PR(D)/2 + PR(E)/3 + PR(F)/2 + PR(C) + PR(G1)/2 + PR(G2)/2 + PR(G3)/2</pre>
			In general, the PageRank value for any page u can be expressed as:
			<br> Eqn.1:   <img src="assets/img/hw/pagerank/eq1.png" width="150" height="20"></p>
		<p> The vertices seen in the right of the formula contain all the webpages that point to target web page ‘u’. The L(v) refers to the out degree of each webpage in the vertices set. The initial rank values of each webpage, like PR’(u), can be any double value. After several iteration calculations, the rank values converge to the stationary distribution regardless of what their initial values are [3].</p>

		<p><strong>Damping factor</strong></p>
		<p>
		The PageRank theory holds that even an imaginary surfer who is randomly clicking on links will eventually stop clicking. The probability, at any step, that the person will continue is a damping factor d. Various studies have tested different damping factors, but it is generally assumed that the damping factor will be around 0.85. The formula considering damping factor is shown in Eqn.2. N refers to the total number of the unique urls. 
		<br> Eqn.2: <img src="assets/img/hw/pagerank/eq2.png" width="242" height="37"></p>
	</div>

    <h2><a>Execution guide for sample PageRank code</a></h2>
    <div>
        <p>To help you understand the process of PageRank computation better, we offer an executable PageRank java class file in the assignment package. Its usage is:  </p>
		<p><strong>Java SequentialPageRank [input file name] [output file name] [iteration count] [damping factor]</strong></p>
        <p>We also provide a small input file which is based on the web graph shown in Fig.1. You can evaluate the rank values in Fig. 1 by running SequentialPageRank with the following parameters:</p>
        <br><pre><strong>Java  SequentialPageRank    pagerank.input   pagerank.output   10  0.85</strong></pre> 
        <p>To check the accuracy of these output rank values, you can open pagerank.output file and see whether the output results are the same as rank values in Fig. 1. Generally speaking, the larger the number of iterations, the more accurate the computed rank values will be. </p>
    </div>
    <h2><a>Programming Guide for PageRank</a></h2>

    <div>
    	<p><strong>Input Data format</strong></p>
        <p>The input data for PageRank application is the web graph in adjacency matrix format [4]. In our sample program, it transfers the web graph into a simplified adjacency matrix. The following steps were performed to construct an adjacency matrix for the web graph in Fig.1: </p>
		<ol>
			<li>Construct a set of tuples that describe the web graph
				structure: WebG = {(A,null), (B, C), (C, B) (D, A, B), (E, B D F),
				(F, B E), (G1, B E), (G2, B E), (G3, B E), (G4, E), (G5, E)</li>
			<li>Map letters to numbers. A->0, B->1, C->2, D->3, E->4, F->5,
				G1->6, G2->7, G3->8, G4->9, G5->10</li>
			<li>Construct the simplified adjacency matrix based on
				information in steps 1,2. 
				<p>0</p>
				<p>1 2</p>
				<p>2 1</p>
				<p>3 0 1</p>
				<p>4 1 3 5</p>
				<p>5 1 4</p>
				<p>6 1 4</p>
				<p>7 1 4</p>
				<p>8 1 4</p>
				<p>9 4</p>
				<p>10 4</p>
			</li>
		</ol>
	</div>
    <h2><a> References </a></h2>

	<ol>		
		<li>
			<a href="http://en.wikipedia.org/wiki/PageRank">http://en.wikipedia.org/wiki/PageRank</a>
		</li>
		<li>
			<a href="http://en.wikipedia.org/wiki/Markov_chain">http://en.wikipedia.org/wiki/Markov_chain</a>
		</li>
		<li>
			Sergey Brin and Lawrence Page, <a
				href="http://infolab.stanford.edu/~backrub/google.html">The
				Anatomy of a Large-Scale </a><a
				href="http://infolab.stanford.edu/~backrub/google.html">Hypertextual</a>
			<a href="http://infolab.stanford.edu/~backrub/google.html"> Web
				Search Engine</a>, Stanford University, WWW7 Proceedings of the seventh
			international conference on World Wide Web 7, 1998
		</li>
		<li>
			<a href="http://en.wikipedia.org/wiki/Adjacency_matrix">http://en.wikipedia.org/wiki/Adjacency_matrix</a>
		</li>
	
	</ol>	
</div>
