<div id="accordion">
<h1>
    Goal
</h1>

<div>
    <p>By this point you should have gone over the sections concerning Hadoop Setup and a few Hadoop programs. Now you are going to blend these applications by implementing a parallel version of
        <a href="http://blast.ncbi.nlm.nih.gov/Blast.cgi">BLAST (Basic Local Alignment Search Tool)</a> using the programming interfaces of the Hadoop MapReduce framework. Note that this application is written in &quot;Map-Only&quot; fashion, which means no reduce code is necessary.</p>
</div>

<h1>
    Deliverables
</h1>

<div>
    <p>
        You are required to turn in the following items in a zip file (<strong>username_HadoopBlast.zip</strong>)
        in this assignment:
    </p>
    <ol>
        <li>The source code of Hadoop Blast you implemented.</li>
        <li>Technical report (username_HadoopBlast_report.docx) that answers the following questions:</li>
    <ul>
        <li>What is Hadoop Distributed Cache and how is it used in this program? </li>
        <li>Write the two lines that add and receive values from Distributed cache. Also include the method and class information.</li>
        <li>In previous projects we used Hadoop’s TextInputFormat to feed in the file splits line-by-line to map tasks. 
        In this program, however, we want to feed in a whole file to a single map task. What is the technique used to achieve this? Also briefly explain what are the key and value pairs 
        you receive as input to a map task. What methods are responsible for producing these pairs and in which class?
        </li>
        <li>Do you think this particular implementation will work if the input files are larger than the default HDFS block size?
        Briefly explain why. [Hint: you can test what will happen by concatenating the same input file multiple times to create a 
        larger input file in the resources/blast_input folder]</li>
        <li>If you wanted to extend this program such that all output files will be concatenated into a single file, what key and value pairs 
        would you need to emit from the map task? Also, how would you use these in the reduce that you would need to add?</li>
    </ul>
    <li>The 4 output FASTA files: celllines_1.fa to celllines_4.fa.</li>
    </ol>
    <p>Points will be reduced (maximum 0.5 points) if the filename or
        directory structure are different from instructed above.</p>
</div>

<h1>Evaluation</h1>

<div>
    <p>The point total for this project is 10, where the
        distribution is as follows:</p>
    <ol type="a">
        <li>Completeness of your code and output (3 points)</li>
        <li>Correctness of written report (7 points)</li>
    </ol>
</div>

<h1>Introduction</h1>

<div>
    <p>Hadoop-Blast is an advanced Hadoop program which helps BLAST, a bioinformatics application, to utilize the computing capability of Hadoop. This exercise shows the details of its implementation, and provides an example of how to handle similar approaches in other applications. <br />
    </p>
    <p>BLAST is one of the most widely used bioinformatics applications written in C++. The version we are using is v2.2.23, which houses new features and better performance. The database used in the following settings is a subset of a full 8.5GB (<a href="http://www.ncbi.nlm.nih.gov/books/NBK1762/">nr</a>) database; its full name is Non-redundant protein sequence database. Optionally, for more details on how to run the BLAST binary, please see <a href="http://salsahpc.indiana.edu/tutorials/hadoopblastex1.html">Big Data for Science tutorial page for Blast Installation (NOT required for the assignment)</a>.</p>
    <p>In this project, we have provided a sketch code which contain a java class/file for you
    to implement:</p>
    <ol>
     
        <li>RunnerMap.java: The pleasingly-parallel/map-only Map class which takes the prepackaged <a href="http://salsahpc.indiana.edu/tutorials/apps/BlastProgramAndDB.tar.gz">Blast (v2.2.23) Binary Program and optimized database</a> from Hadoop Distributed Cache, then executes BLAST binary as java external process with the  assigned FASTA file. These are passed as key-value pairs of &lt;filename, filepath on HDFS&gt; handled by a provided customized Hadoop MapReduce InputFormat DataFileInputFormat.java.</li>
    </ol>
    <p>The detail dataflow can be seen in Figure 1. You will implement the RunnerMap.java, which copies the distributed cache and assigned FASTA file to local, then runs the BLAST binary with correct parameters.</p>

    <p align="center"><img src="assets/img/hw/hadoopblast/hadoop_blast.png" alt=""
                           width="700"/></p>

    <p align="center">Figure 1. Hadoop Blast dataflow</p>

    <p align="justify">Normally for any Hadoop MapReduce program, input data is uploaded and stored
        in the Hadoop Distributed File System (HDFS) before computation in order to generate &lt;key, value&gt;
        pairs to the mapper. Initially, the BLAST input data is a set of FASTA files located in the local file system. Then it will be uploaded to the HDFS and
        distributed across the compute nodes. Hadoop framework reads the application records from
        HDFS with the InputFormat interface and generates &lt;key, value&gt; pair input streams; here, we use a provided 
        customized Hadoop MapReduce InputFormat DataFileInputFormat.java to generate key-value pairs of &lt;filename, filepath on HDFS&gt;. For this Hadoop Blast program,
        the map function initially sets up the distributed cache and generates the two absolute location filepaths for BLAST binary and BLAST Database. Afterwards it copies the assigned FASTA file to local disk by looking up the file from HDFS and generating an absolute  filepath. Once this is accomplished and file dependencies are stored in the local disk, we call an external java process and execute the BLAST binary with the correct parameters. Finally, the output FASTA file of BLAST binary will be uploaded back to HDFS.</p>
</div>

<h1>Sketch for Hadoop Blast</h1>


<div>
    <p>You need to complete one file in the provided package inside &quot;cgl/hadoop/apps/runner&quot;:
        RunnerMap.java.
        Code snapshots are shown below.</p>

    <p><strong>RunnerMap.java</strong>
    </p>

    <!-- HTML generated using hilite.me -->
    <div style="background: #ffffff; overflow: auto; width: auto;">

        <script src="https://gist.github.com/cloudmooc/6323972.js"></script>

    </div>
    
    <p>&nbsp;</p>
    <p>In addition, if you need to understand the dataflow and main program, please look into the DataAnalysis.java.</p>
    
    <p><strong>DataAnalysis.java</strong>
    </p>

    <!-- HTML generated using hilite.me -->
    <div style="background: #ffffff; overflow: auto; width: auto;">

      <script src="https://gist.github.com/cloudmooc/6322913.js"></script>

    </div>

</div>
<h1>Edit</h1>

<p>The sketch code is stored within the provided <a
        href="http://cloudmooc.soic.indiana.edu:10002/mooc-ubuntu1204.ova">VirtualBox</a> image. Use linux text editor vi/vim to add your code.</p>

<div><br/>

    <div class="dp-highlighter">
        <div class="bar">
<pre>
$ cd /root/MoocHomeworks/HadoopBlast/
$ vim src/cgl/hadoop/apps/runner/RunnerMap.java
</pre>
        </div>
    </div>
    <h2>Compile and run your code</h2>

    <p>Use the one-click script compileAndExecHadoopBlast.sh as provided. Standard
        error messages such as &ldquo;compile errors, execution errors, etc.&rdquo; will be
        redirected on the screen. Follow the same debugging format.</p>

    <div><br/>

        <div class="dp-highlighter">
            <div class="bar">
<pre>
$ cd /root/MoocHomeworks/HadoopBlast/

# usage: ./compileAndExecHadoopBlast.sh
$ ./compileAndExecHadoopBlast.sh 
</pre>
            </div>
        </div>
        <h2>View the result</h2>

        <p>The result is generated at /root/MoocHomeworks/HadoopBlast/output/HDFS_blast_output. There should be 4 output FASTA files with .fa extension.</p>

        <div><br/>

            <div class="dp-highlighter">
                <div class="bar">
<pre>
$ cd /root/MoocHomeworks/HadoopBlast/output/HDFS_blast_output

</pre>
                </div>
            </div>

        </div>
</div>
    </div>
</div>
