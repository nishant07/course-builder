7,Expectations and Projects,1,Computational Clusters,,,//www.google.com/edu/coursebuilder/courses/pswg/1.2/assets/notes/Lesson2.1/Lesson2.1Whensearchresultssuggestsomethingnew.html,xQNuLjickxc,"<p>Examples and definitions are given for SaaS, PaaS, and IaaS. Computational models must be designed with the problems and effective resources in mind. A demonstration of cloud use for Bioinformatics on the FutureGrid educational testbed shows how clouds offer advantages of provisioning and virtual cluster support. Overhead and performance issues are touched upon through charts showing the use of three different virtual clusters.</p>",
7,Expectations and Projects,2,Term Projects 1,,,//www.google.com/edu/coursebuilder/courses/pswg/1.2/assets/notes/Lesson2.2/Lesson2.2Thinkingmoredeeplyaboutyoursearch_Te.html,DYG6_bUGsqY,"<p>The work of previous B649 students is presented, covering a variety of topics and software: HBase, DryadLINQ, virtualization, commercial cloud storage, and IU’s Twister iterative MapReduce.</p>",
7,Expectations and Projects,3,Term Projects 2,,,//www.google.com/edu/coursebuilder/courses/pswg/1.2/assets/notes/Lesson2.3/Lesson2.3Understandingyouroptionsfordifferent.html,8EdxkDiUpKI,"<p>This lecture offers further examples of prior student projects in areas like cloud storage, infrastructure and platforms, as well as high level languages like Apache Pig. Other topics cover MapReduce in Single Program Multiple Data mode, genetic algorithms in MapReduce, Hadoop supporting recommender systems, K-means clustering, etc. Following this the benefits/vulnerabilities of clouds and some of their most well-known programs are showcased in other research assignments. In conclusion, we have a list of the requirements for current student project submissions.</p>",
7,Expectations and Projects,4,MapReduce Models,,,//www.google.com/edu/coursebuilder/courses/pswg/1.2/assets/notes/Lesson2.2/Lesson2.2Thinkingmoredeeplyaboutyoursearch_Te.html,WK6eH_bCqW4,"<p>An introduction to the idea of iterative MapReduce. An overview of other MapReduce models follows. Map Only model has parallel map tasks with no communication between them. Classic MapReduce involves parallel map tasks and reduce tasks which aggregate output and allow legacy code. Loosely Synchronous is an MPI model used in computation and communication of scientific applications.</p>",
7,Expectations and Projects,5,Designing for Big Data,,,//www.google.com/edu/coursebuilder/courses/pswg/1.2/assets/notes/Lesson2.2/Lesson2.2Thinkingmoredeeplyaboutyoursearch_Te.html,RJ46v2WMwj8,"<p>CPU performance increases according to Moore’s Law can no longer keep up with the high volume of data being generated. Multi-core architecture is a response to this issue. It requires runtime approaches supporting parallelism, either data-centric for higher throughput (MapReduce) or the traditional HPC approach for optimized computation performance (MPI). MapReduce allows for moving computation to the data. A diagram illustrates the base MapReduce process. MapReduce is designed to improve I/O and handle intermediate data, task scheduling, and fault tolerance. Versions of MapReduce like Hadoop, Dryad and MPI boast different features and programming languages.</p>",
7,Expectations and Projects,6,Twister Iterative MapReduce,,,//www.google.com/edu/coursebuilder/courses/pswg/1.2/assets/notes/Lesson2.2/Lesson2.2Thinkingmoredeeplyaboutyoursearch_Te.html,UJHQ3VvWOTA,"<p>Iterative MapReduce was introduced to support high performance systems. It runs iterations of the map/reduce cycles. Data mining algorithms like K-means run numerous iterations. Static data such as data points in K-means does not change, while variable data can alter between each iteration. A naïve iterative MapReduce model can generate huge overhead owing to constantly referencing static data.  This can be overcome with long-running map/reduce tasks that distinguish between static and variable data. You can also accelerate the intermediate data transfer or combine the output of all reduce tasks. Iterative MapReduce is shown in the Twister program, which uses the combine output method and determines at the end of every iteration whether to stop or continue with further iterations. The master node in Twister is the Twister Driver, and the slave nodes are Twister Daemons. Twister stores I/O data in partition files. Three MapReduce patterns in Twister: 1) Large input data, reduced in the end; 2) Data size is constant; 3) Data volume increases after MapReduce execution. Data Manipulation Tool handles data loading and uses metadata to keep track of data in partitions. Twister employs static scheduling. Fault tolerance is reserved for failures that terminate running tasks. Static data can then be used to reassign the failed iterations. A list of Twister APIs is given.</p>",
7,Expectations and Projects,7,Application Performance,,,//www.google.com/edu/coursebuilder/courses/pswg/1.2/assets/notes/Lesson2.2/Lesson2.2Thinkingmoredeeplyaboutyoursearch_Te.html,n7RVGrC-wcs,"<p>This video showcases examples of work done comparing Twister results with Hadoop, MPI and DryadLINQ. The first is Map Only with CAP3 DNA Sequence Assembly, followed by Classic MapReduce with Pair-wise Sequences and High-Energy Physics, Iterative with K-means clustering, PageRank and Multi-dimensional Scaling, and finally Loosely Synchronous with Matrix Multiplication Algorithms. In all cases, Twister outperforms or is close to the competition.</p>",
7,Expectations and Projects,8,Twister K-means Explained,,,//www.google.com/edu/coursebuilder/courses/pswg/1.2/assets/notes/Lesson2.2/Lesson2.2Thinkingmoredeeplyaboutyoursearch_Te.html,WQPNzI_qiB4,"<p>Twister is applied to K-means Clustering. K-means develops a set number of clusters by creating cluster centers (centroids) that encompass the data points after successive proximity calculations. Parallelization of K-means is accomplished in the partitions, and the final centroids are determined in the Reduce step. A sample of K-means Clustering code follows, after which Twister is shown being used to determine centroids on K-means. Several questions are posed pertaining to the features of Twister. The results of a Twister K-means run are compared with those from a sequential run. Shown here, as the number of data points increases, Twister’s runtimes get progressively faster. In a final set of runs against Hadoop, DryadLINQ, and MPI, Twister outperforms all but MPI.</p>",
7,Expectations and Projects,9,Twister K-means Code,,,//www.google.com/edu/coursebuilder/courses/pswg/1.2/assets/notes/Lesson2.2/Lesson2.2Thinkingmoredeeplyaboutyoursearch_Te.html,kT135DLNwbE,"<p>A more detailed look is taken at the code used to run Twister K-means. MapReduce has many programs designed around its setup, including other iterative versions like Haloop, Pregel, and Spark. Twister can extend the use of traditional MapReduce to more complex applications.</p>",